{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Introduction:\n",
    "\n",
    "This project is intended to be an initial exploration and creation of a potential classification machine learning algorithm that can be used and integrated into the Olin ABE(Amorphous Blob of Events), a platform that enables tthe creation of digitial experiences that share information about past, present, and upcoming events. \n",
    "\n",
    "Today email is an essential part of how Olin communicates and conveys information, there exists lists such as carpediem which are used solely to convey information about things that are happening. Ideally this information could be automatically captured by ABE amd turned into an event; however, the format of carpediem emails is non standard. Thus, a system must be designed and created to extract, load, and create an appropriate event for the email depending on the information inside. One aspect of this system would be a method to create an appropriate tag or tags for the project based on the content of the email. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scrapper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data scrapper uses Poplib to access and pull all the new email information from the olinsnapshot@gmail.com account. It parses it and stores into an appropriate csv file. Annotation/Labeling of the tag will need to be done independantly on the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data exploration sought to find patterns about the subject and body text data that is provided to us. However, the serious lack of sufficient data resulted in sub-par visualizations as it was hard to generalize about the words within the text of the body of the email. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried two main algorithms: Bag of Words with SciKit Learn and Naive Bayesian by Hand\n",
    "\n",
    "Bag of words consists of transforming each data point (sentence) into a sparse vector that corresponds a consistent row of word - index relationship. This can be easily done using scikit-learns Count Vectorizer. However the preprocessing of the data can result in different results. I tried to use the insights from the data exploration to in addition to removing a list of stopwords from online to improve the choosing the most influential word. However, because the exploration lacked enough data to really extract useful features and insights I stuck with the original model and vectorizing tool, which is able to refer to outside langauge data.\n",
    "\n",
    "We first followed the bag of words kaggle tutorial (https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) to create a (256060, 1000) bag of words as a feature map, and applied random forest classification to fit our trainning data. Due to limitedness of memory, we were only able to perform random forest classification at tree level of 10.\n",
    "\n",
    "Naive Bayesian is a simple but powerful probabilistic classifier that relies on applying Bayeâ€™s theorem to data by assuming that the features (in a bag of words case each word feature) are strongly independent. I specifically chose to do our own implementation because of the simplistic nature but also common application of this technique in sentiment analysis. To learn about the math and its applications to sentiment analysis I followed http://blog.datumbox.com/machine-learning-tutorial-the-naive-bayes-text-classifier/ as a guide and then created our own implementation of the mathematical equations for Multinomial Bayesian Classifier, Multinomial Bayesian Classifier with smoothing, and Binarized Multinomial Bayesian Classifier with smoothing.\n",
    "\n",
    "Math and Code Explanation:\n",
    "\n",
    "To apply naive bayesian to our this data set we have 28 separate outcomes (tags) that we will need to calculate the probability of for each email we are provided and need a set of 28 class probabilities and a reference set of 28 outcome probabilities for each word.\n",
    "\n",
    "We can get the class probabilities fairly easily by counting the number of phrases with that sentiment and dividing by the total number of phrases\n",
    "\n",
    "We will can get the frequency per word for each probability and then calculate the probability for each of the class probabilities by dividing the the total number of occurrences that word occurs in any given sentiment outcome by the frequency of word\n",
    "\n",
    "Then, to get the probability of a phrase or sentence we multiply the probability for each word in that phrase against the probability of any document that expresses that tag.\n",
    "\n",
    "Finally the model can be improved by adding smoothing factors to the calculation of the word probabilities.\n",
    "\n",
    "I implemented both\n",
    "\n",
    "Multinomial Naive Bayesian\n",
    "![Multinomial Naive Bayesian](./images/n_b_equation.png) \n",
    "\n",
    "Multinomial Naive Bayesian w/ Smoothing\n",
    "![Multinomial Naive Bayesian w/ Smoothing](./images/n_b_s_equation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the classification algorithm: the code to load datasets is ready. The current data + model for the sake of scope is only designed to choose one tag when many events have multiple tags (for example, many events often can include a food tag). \n",
    "\n",
    "Possible extensions are \n",
    "1. Gathering more data and rerunning the data exploration code to see if there are more noticeble trends that can be useful to us later.\n",
    "2. Extending the data exploration to exploring the temporal data provided in date and time.\n",
    "3. Extending into other multiclassification algorithms such as neural networks as well as applying the naive bayesian work already done.\n",
    "\n",
    "There may be additional visualizations that may be useful to extract additional features to assist in classificiation. The current _ success rate is also limited by the amount of data (currently N = )\n",
    "\n",
    "Working through the data processing, visualization, and training processes has given lot's of insight into what would be necessary to automatically create events from an email. \n",
    "\n",
    "The biggest risks are in the \n",
    "1. High variability of emails that include non event items such as\n",
    "    a. things for free \n",
    "    b. things for sale\n",
    "    c. housing offers\n",
    "2. Variable inclusion and formating of temporal and location data\n",
    "3. Dealing with Re:'s and email chains\n",
    "\n",
    "Given the constraints I propose the following system:\n",
    "\n",
    "![System Diagram](./images/system.jpg)\n",
    "\n",
    "Through Poplib each time an email is forwarded it will be grabbed and passed into MongoDB. Because Poplib only looks at new emails it will ignore the old ones, each time it pulls from the olinsnapshot@gmail.com account. The information will be automatically stored in the MongoDB database of the ABE backend. An adapted version of the ABE_Tagger could run concurrently with the trained classification algorithm and apply it to each entry. A seperate Event_Manager would take each individual entry and determine whether it is unique and thus create an appropriate new event or identify an older event and append the new body information onto the already existing event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
